{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Application Exercize\n",
    "## Regression\n",
    "\n",
    "The task of this exercize is to implement a complete Data Driven pipeline (load, data-analysis, visualisation, model selection and optimization, prediction) on a specific Dataset. In this exercize the challenge is to perform a regression with different models to find the most accurate prediction.  \n",
    "\n",
    "\n",
    "## Dataset \n",
    "The notebook will upload a public available dataset: https://archive.ics.uci.edu/ml/datasets/Airfoil+Self-Noise\n",
    "<blockquote>\n",
    "  <b>Source:</b>\n",
    "    Donor: Dr Roberto Lopez robertolopez@intelnics.com Intelnics\n",
    "    <br/>\n",
    "    Creators: Thomas F. Brooks, D. Stuart Pope and Michael A. Marcolini NASA\n",
    "    <br/>\n",
    "    <b>Data Set Information:</b>\n",
    "    NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections \n",
    "    conducted in an anechoic wind tunnel.\n",
    "    The NASA data set comprises different size NACA 0012 airfoils at various wind tunnel speeds and angles of attack. The span of the \n",
    "    airfoil and the observer position were the same in all of the experiments. \n",
    "    <br/>\n",
    "    <b>Attribute Information:</b>\n",
    "    This problem has the following inputs: \n",
    "    <code><br/> 1. Frequency, in Hertzs.                          </code>\n",
    "    <code><br/> 2. Angle of attack, in degrees.                   </code>\n",
    "    <code><br/> 3. Chord length, in meters.                       </code>\n",
    "    <code><br/> 4. Free-stream velocity, in meters per second.    </code>\n",
    "    <code><br/> 5. Suction side displacement thickness, in meters.</code>\n",
    "    <br/>\n",
    "    The only output is:\n",
    "    <code><br/>6. Scaled sound pressure level, in decibels.        </code>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algebra\n",
    "import numpy as np\n",
    "# data structure\n",
    "import pandas as pd\n",
    "# data visualization\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "#file handling\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load\n",
    "The process consist in downloading the data if needed, loading the data as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "filename  = \"airfoil_self_noise.dat\"\n",
    "separator = '\\t'\n",
    "columns   = None\n",
    "\n",
    "#if the dataset is not already in the working dir, it will download\n",
    "my_file = Path(filename)\n",
    "if not my_file.is_file():\n",
    "  print(\"Downloading dataset\")\n",
    "  !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00291/airfoil_self_noise.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to semplificate the load of dataset, in case it is a csv, tsv or excel file\n",
    "#output is a pandas dataframe \n",
    "def load_csv(filename,separator,columns):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        csv_table = pd.read_csv(filename,sep=separator,names=columns)\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        csv_table = pd.read_excel(filename,names=columns)\n",
    "    print(\"n. samples: {}\".format(csv_table.shape[0]))\n",
    "    print(\"n. columns: {}\".format(csv_table.shape[1]))\n",
    "\n",
    "    return csv_table #.dropna()\n",
    "\n",
    "data = load_csv(filename,separator,columns)\n",
    "#remove any anomalous value (e.g. \"nan\")\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Visualization\n",
    "## Task:\n",
    "* check the first entries of the dataframe\n",
    "* print the names of all columns\n",
    "* Plot pairwise relationships of the dataset (<a href=\"https://seaborn.pydata.org/generated/seaborn.pairplot.html\"> hint</a>)\n",
    "* Plot the correlation matrix (<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\"> Dataframe Correlation</a>, <a href=\"https://seaborn.pydata.org/generated/seaborn.heatmap.html\">heatmap</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the first entries of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the names of all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot pairwise relationships of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and plot the correlation matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "Here the interesting input features and output to predict for the task are selected, the data are opportunelly preprocessed (i.e. normalized), the dataset is splitted in two separate train and test subsets, each model is trained on the training data and evaluated against a test set.<br/>\n",
    "The evaluation metrics list can be found <a href='https://scikit-learn.org/stable/modules/model_evaluation.html'>here</a>\n",
    "\n",
    "## Task\n",
    "* import a metric to evaluate the models (for ex. median_absolute_error, or choose from this <a href='https://scikit-learn.org/stable/modules/model_evaluation.html'>list</a>)\n",
    "* Define a Scaler to standardize the input features and output and apply the transformation to better fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the module needed for the modeling and data mining are imported\n",
    "#Cross-Validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "#Data normalization\n",
    "from sklearn.preprocessing   import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import a metric to evaluate the model\n",
    "#from sklearn... \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of feature and output variable, definition of the size (fraction of the total) of the random selected test set\n",
    "input_features = ['Frequency','Angle of attack','Chord length','Free-stream velocity','Suction side displacement thickness']\n",
    "output         = ['Scaled sound pressure level']\n",
    "test_size      = 0.33\n",
    "random_state   = 0\n",
    "\n",
    "#not preprocessed data\n",
    "unnormalized_X,unnormalized_y = data[input_features],data[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardisation\n",
    "#Define a Scaler to standardize the input features and output\n",
    "\n",
    "\n",
    "#standardize the inputs and outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic train-test dataset random split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to help the display of the results\n",
    "Score_Dict = {}\n",
    "\n",
    "#function introduced to simplifies the following comparison and test of the various\n",
    "#return the trained model and the score of the selected metrics\n",
    "def fit_predict_plot(model,X_train,y_train,X_test,y_test):\n",
    "    model.fit(X_train,y_train.ravel())\n",
    "\n",
    "    pred_normalized_y_test = model.predict(X_test)\n",
    "    pred_y_test            = scaler_y.inverse_transform(pred_normalized_y_test)\n",
    "    real_y_test            = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "#Alternative metrics are listed here:https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    mse_score = median_absolute_error(real_y_test,pred_y_test)\n",
    "    \n",
    "    model_name = type(model).__name__\n",
    "    if(model_name=='GridSearchCV'):\n",
    "        model_name ='CV_'+type(model.estimator).__name__\n",
    "    \n",
    "    Score_Dict[model_name]=mse_score\n",
    "\n",
    "    plt.figure(figsize=[5,5])\n",
    "    plt.scatter(real_y_test,pred_y_test)\n",
    "    plt.plot([real_y_test.min(),real_y_test.max()],[real_y_test.min(),real_y_test.max()],'k:')\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"Median Absolute Error: {:.2f}\".format(mse_score))\n",
    "    plt.xlabel('True Scaled sound pressure level')\n",
    "    plt.ylabel('Predicted Scaled sound pressure level')\n",
    "    \n",
    "    return model,mse_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation \n",
    "As example a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\">linear regression</a> is implemented and the results are shown. \n",
    "\n",
    "## Tasks\n",
    "* Implement a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\">Lasso Regression</a> \n",
    "    * hyper-parameter alpha = 0.1\n",
    "    * Remember what we have seen regarding Lasso and regularisation (hint: check the trained coefficients)\n",
    "* Implement a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\">Epsilon-Support Vector Regression</a> with the following hyper-parameters:\n",
    "    * C = 100\n",
    "    * kernel='rbf'\n",
    "    * gamma = 'auto'\n",
    "* Implement a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">Random Forest Regressor</a> with the following hyper-parameter:\n",
    "    * n_estimators=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the module that allows to access the Linear Regression, Lasso and Ridge algorithm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization, fit and evaluation of the model\n",
    "model = linear_model.LinearRegression()\n",
    "basic_linear_model, basic_linear_score = fit_predict_plot(model,X_train,y_train,X_test,y_test)\n",
    "\n",
    "#check the output of the model\n",
    "print(basic_linear_model.coef_)\n",
    "print(basic_linear_model.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter definition\n",
    "\n",
    "\n",
    "#initialization, fit and evaluation of the model\n",
    "\n",
    "\n",
    "#Check the trained parameters (coefficients)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html\">Epsilon-Support Vector Regression</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the correct module from scikit-learn\n",
    "\n",
    "\n",
    "# hyper-parameter definition\n",
    "\n",
    "\n",
    "#initialization, fit and evaluation of the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "A <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">Random Forest Regressor</a> is a meta estimator that fits a number of classifying decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the correct module from scikit-learn\n",
    "\n",
    "\n",
    "# hyper-parameter definition\n",
    "\n",
    "\n",
    "#initialization, fit and evaluation of the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters tuning and Cross Validation\n",
    "Finding the best hyperparameter of interest without writing hundreds of lines of code is an important efficiency gain\n",
    "<br/>CV is to avoid bias in the performance evaluation\n",
    "<br/>\n",
    "For the Tuning a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">Grid Search with Cross Validation</a> is used. <br />\n",
    "<code>cv :: Determines the cross-validation splitting strategy.</code>\n",
    "\n",
    "\n",
    "As example a gridsearch with cross validation is implemented using:\n",
    "* estimator = KernelRidge\n",
    "* hyper-parameters : \n",
    "    * kernel: polynomial, rbf\n",
    "    * degree: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] = np.arange(10)\n",
    "    * alpha : [0.01, 0.1, 1, 10, 100]        = np.logspace(-2,2,5) \n",
    "\n",
    "\n",
    "## Tasks:\n",
    "\n",
    "* Import the module that automates the search over specified (hyper-)parameter values for an estimator\n",
    "* Implement a 5-fold splitting strategy for the Cross Validation\n",
    "* Implement the following Gridsearch models:\n",
    "* Lasso:\n",
    "    * alpha = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    * which alpha is the best? \n",
    "* Support Vector:\n",
    "    * kernel = poly, rbf\n",
    "    * C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "* Random Forest:\n",
    "    * n_estimator: [10.,  120.,  230.,  340.,  450.,  560.,  670.,  780.,  890., 1000.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the module from scikit-learn that perform the grid-search\n",
    "\n",
    "\n",
    "#setup the five fold splitting strategy for cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KernelRidge with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define estimator and hyper-parameters range \n",
    "estimator  = KernelRidge()\n",
    "parameters = {'kernel':['polynomial','rbf'],\n",
    "              'degree':np.arange(10),\n",
    "              'alpha':np.logspace(-2,2,5)}\n",
    "\n",
    "#initialized the gridsearch and extract the best model \n",
    "model = GridSearchCV(estimator, parameters,cv=cv,iid=False)\n",
    "\n",
    "#train and evaluate the best model, plot the results \n",
    "cv_krr_model,cv_krr_score = fit_predict_plot(model,X_train,y_train,X_test,y_test)\n",
    "#print best hyper-parameters\n",
    "print(cv_krr_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define estimator and hyper-parameters range \n",
    "\n",
    "\n",
    "\n",
    "#initialized the gridsearch and extract the best model \n",
    "\n",
    "\n",
    "#train and evaluate the best model, plot the results\n",
    "\n",
    "\n",
    "\n",
    "#print the best hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon-Support Vector Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define estimator and hyper-parameters range \n",
    "\n",
    "\n",
    "\n",
    "#initialized the gridsearch and extract the best model \n",
    "\n",
    "\n",
    "#train and evaluate the best model, plot the results\n",
    "\n",
    "\n",
    "\n",
    "#print the best hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define estimator and hyper-parameters range \n",
    "\n",
    "\n",
    "\n",
    "#initialized the gridsearch and extract the best model \n",
    "\n",
    "\n",
    "#train and evaluate the best model, plot the results\n",
    "\n",
    "\n",
    "\n",
    "#print the best hyper-parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the results in a table\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "table = '<table><tr><th> Model</th><th> Accuracy Metric </th></tr>'\n",
    "\n",
    "for key, value in Score_Dict.items():\n",
    "    table +='<tr> <td>'+key+'</td><td>' +'%.2f'%(value)+'</td></tr>'\n",
    "table+='</table>'\n",
    "display(md(table))\n",
    "\n",
    "\n",
    "names = list(Score_Dict.keys())\n",
    "values = list(Score_Dict.values())\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "plt.bar(names, values)\n",
    "plt.ylabel('Accuracy Metric')\n",
    "plt.xticks(rotation=30)\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
