{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of Cross Validation for hyper-parameters selection\n",
    "Cross-validation is a statistical method used to estimate the skill of machine learning models, as mentioned <a href=\"https://machinelearningmastery.com/k-fold-cross-validation/\">here</a>.\n",
    "It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.\n",
    "\n",
    "\n",
    "To be learned: Overfitting, Underfitting (<a href=\"https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690\">further reading</a>), <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\"> Cross Validation </a> for model validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Module\n",
    "\n",
    "#Algebra, Powerful n-dimensional arrays. Numerical computing tools.\n",
    "import numpy as np\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# machine learning library\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset in this way to hide the generating function, so you don't have any expectation :-) \n",
    "y_train = np.array([ 0.99292384, -0.17602701, -0.4310528 , -0.33073868, -0.83399427,\n",
    "       -0.81227499, -0.9457809 , -0.85624286, -0.95165592, -0.92715604,\n",
    "       -1.13032117, -0.88798652, -0.51239893, -0.19203875, -0.20370536])\n",
    "\n",
    "X_train = np.array([0.07103606, 0.38344152, 0.4236548 , 0.43758721, 0.52889492,\n",
    "       0.54488318, 0.5488135 , 0.56804456, 0.60276338, 0.64589411,\n",
    "       0.71518937, 0.79172504, 0.891773  , 0.92559664, 0.96366276])\n",
    "\n",
    "y_test = np.array([ 0.93275396,  0.95087121,  0.86633854,  0.71088378,  0.81383568,\n",
    "        0.64752137,  0.39816723,  0.46616733,  0.1767985 ,  0.11331356,\n",
    "        0.01877015, -0.20207215, -0.25619809, -0.63903644, -0.60715212,\n",
    "       -0.83064306, -0.94393689, -0.98686169, -1.00777581, -0.99291688,\n",
    "       -1.11065294, -0.87346734, -0.86100918, -0.98131337, -0.57717027,\n",
    "       -0.4155853 , -0.35053048, -0.33729401, -0.26885726,  0.10544517])\n",
    "X_test = np.array([0.        , 0.03448276, 0.06896552, 0.10344828, 0.13793103,\n",
    "       0.17241379, 0.20689655, 0.24137931, 0.27586207, 0.31034483,\n",
    "       0.34482759, 0.37931034, 0.4137931 , 0.44827586, 0.48275862,\n",
    "       0.51724138, 0.55172414, 0.5862069 , 0.62068966, 0.65517241,\n",
    "       0.68965517, 0.72413793, 0.75862069, 0.79310345, 0.82758621,\n",
    "       0.86206897, 0.89655172, 0.93103448, 0.96551724, 1.        ])\n",
    "\n",
    "np.random.seed(0)\n",
    "n_samples = 15\n",
    "degrees = [1, 4, 12]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment n.1 training a model without a data validation strategy\n",
    "\n",
    "### Evaluate the models on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each hyper-parameter (degree) initialized and fit a model (linear regression)\n",
    "#check the performance of that model using the mean squared error metrics\n",
    "\n",
    "\n",
    "trained_model = [0,0,0]\n",
    "for i,d in enumerate(degrees):\n",
    "    \n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=True)\n",
    "    linear_regression = LinearRegression()\n",
    "    trained_model[i] = Pipeline([(\"polynomial_features\", polynomial_features),(\"linear_regression\", linear_regression)])\n",
    "    trained_model[i].fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "    # Evaluate the models performance on the train dataset\n",
    "    train_scores = mean_squared_error(y_train,trained_model[i].predict(X_train[:, np.newaxis]))\n",
    "\n",
    "    #print the results\n",
    "    print(\"Degree: {} :: Train MSE = {:.5f}\".format(d,train_scores))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models on the test data\n",
    "what would you expect?  what do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the performance of the trained model on the test dataset\n",
    "for i,d in enumerate(degrees):\n",
    "    test_scores = mean_squared_error(y_test,trained_model[i].predict(X_test[:, np.newaxis]))\n",
    "    print(\"Degree: {} :: Test MSE = {:.5f}\".format(d,test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment n.2 training a model with a model validation strategy\n",
    "Imagine not to have the test dataset, what would you do?\n",
    "\n",
    "Cross-Validation allows to get similar information as in the case of evaluating against a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each hyper-parameter (degree) initialized and fit a model (linear regression) to train dataset only(!!!)\n",
    "#check the performance of that model using the mean squared error metrics and cross validation\n",
    "\n",
    "for i,d in enumerate(degrees):\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X_train[:, np.newaxis], y_train)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    cv_scores = cross_val_score(pipeline, X_train[:, np.newaxis], y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "    print(\"Degree: {} :: Train CV MSE = {:.5f}\".format(d,-cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For fun, let's have a look at the data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for i,d in enumerate(degrees):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    X_fun = np.linspace(0, 1, 1000)\n",
    "    plt.plot(X_fun, trained_model[i].predict(X_fun[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_fun, np.cos(1.5 * np.pi * X_fun), label=\"True function\")\n",
    "    plt.scatter(X_train, y_train, edgecolor='b', s=20, label=\"Train Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree: {}\".format(d))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
