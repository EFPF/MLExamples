{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "innovative-vacuum",
   "metadata": {
    "id": "consistent-split"
   },
   "source": [
    "# ML Application Exampls\n",
    "## Clustering: Seeds Data Set \n",
    "\n",
    "The task of this example is to implement a clustering algorithm within a ML pipeline (load, data-analysis, visualisation, model selection and optimization, prediction) on a specific Dataset. \n",
    "\n",
    "\n",
    "## Dataset \n",
    "The notebook will upload a public available dataset: https://archive.ics.uci.edu/ml/datasets/seeds\n",
    "\n",
    "Measurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.\n",
    "\n",
    "  <b>Source:</b>\n",
    "        \n",
    "  Magorzata Charytanowicz, Jerzy Niewczas <br />\n",
    "  Institute of Mathematics and Computer Science, <br /> \n",
    "  The John Paul II Catholic University of Lublin, Konstantynw 1 H, PL 20-708 Lublin, Poland <br />\n",
    "        e-mail: mchmat@kul.lublin.pl , jniewczas@kul.lublin.pl <br />\n",
    "\n",
    "  Piotr Kulczycki, Piotr A. Kowalski, Szymon Lukasik, Slawomir Zak <br />\n",
    "  Department of Automatic Control and Information Technology, <br />\n",
    "  Cracow University of Technology, Warszawska 24, PL 31-155 Cracow, Poland <br />\n",
    "  and <br />\n",
    "  Systems Research Institute, Polish Academy of Sciences, Newelska 6, PL 01-447 Warsaw, Poland <br />\n",
    "  e-mail: kulczycki@ibspan.waw.pl , pakowal@ibspan.waw.pl , slukasik@ibspan.waw.pl , slzak@ibspan.waw.pl\n",
    "    \n",
    "   <br/>\n",
    "    <b>Data Set Information:</b>\n",
    " The examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected for\n",
    "the experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.\n",
    "\n",
    "The data set can be used for the tasks of classification and cluster analysis.\n",
    "        \n",
    "<b>Attribute Information:</b>\n",
    "    All attributes are continuous, with the exception of the class attribute.\n",
    "    To construct the data, seven geometric parameters of wheat kernels were measured:\n",
    "    <ul>\n",
    "    <li> area A, </li>\n",
    "    <li> perimeter P, </li>\n",
    "    <li> compactness C = 4*pi*A/P^2, </li>\n",
    "    <li> length of kernel, </li>\n",
    "    <li>width of kernel, </li>\n",
    "    <li> asymmetry coefficient </li>\n",
    "    <li> length of kernel groove. </li>\n",
    "    </ul>\n",
    "All of these parameters were real-valued continuous.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-philadelphia",
   "metadata": {
    "id": "hollow-mouth"
   },
   "outputs": [],
   "source": [
    "# algebra\n",
    "import numpy as np\n",
    "# data structure\n",
    "import pandas as pd\n",
    "# data visualization\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "#file handling\n",
    "from pathlib import Path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-peripheral",
   "metadata": {
    "id": "higher-click"
   },
   "source": [
    "# Data load\n",
    "The process consist in downloading the data if needed, loading the data as a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-warrant",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "healthy-house",
    "outputId": "cc4ba627-7fcc-48d0-ca71-508a6b18a620"
   },
   "outputs": [],
   "source": [
    "filename  = \"seeds_dataset.txt\"\n",
    "\n",
    "#if the dataset is not already in the working dir, it will download\n",
    "my_file = Path(filename)\n",
    "if not my_file.is_file():\n",
    "  print(\"Downloading dataset\")\n",
    "  !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt\n",
    " \n",
    "\n",
    "\n",
    "sep = '\\t'\n",
    "columns = ['area',\n",
    " 'perimeter',\n",
    " 'compactness',\n",
    " 'length_kernel',\n",
    " 'width',\n",
    " 'asymmetry',\n",
    " 'length_groove',\n",
    " 'unknown_class']\n",
    "\n",
    "all_data          = pd.read_csv(filename,sep=sep,names=columns,usecols=np.arange(8),index_col=None)\n",
    "all_data          = all_data.dropna()\n",
    "\n",
    "data          = all_data[columns[:7]]\n",
    "unknown_class = all_data[columns[7]]\n",
    "\n",
    "print(\"n. samples: {}\".format(data.shape[0]))\n",
    "print(\"n. columns: {}\".format(data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-breakdown",
   "metadata": {
    "id": "sophisticated-weather"
   },
   "source": [
    "# Data Analysis and Visualization\n",
    "In this section confidence with the data is gained, data are plotted and cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-psychiatry",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "heavy-effort",
    "outputId": "1ea87378-8c20-4dbb-b809-99d8e931973c"
   },
   "outputs": [],
   "source": [
    "#How does the dataset look like? \n",
    "print(all_data.head())\n",
    "print('Columns names:',all_data.columns.values)\n",
    "print(\"Classes to predict in the data:\",all_data['unknown_class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-savings",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "heavy-effort",
    "outputId": "1ea87378-8c20-4dbb-b809-99d8e931973c"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(all_data,hue = 'unknown_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-millennium",
   "metadata": {
    "id": "disturbed-brazilian"
   },
   "source": [
    "# Machine Learning\n",
    "## Clustering metrics\n",
    "\n",
    "\n",
    "\n",
    "See the Clustering performance evaluation section of the user guide for further details.\n",
    "\n",
    "The sklearn.metrics.cluster submodule contains evaluation metrics for cluster analysis results. There are two forms of evaluation:\n",
    "\n",
    "- supervised, which uses a ground truth class values for each sample.\n",
    "\n",
    "- unsupervised, which does not and measures the ‘quality’ of the model itself.\n",
    "\n",
    "Look at https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-coverage",
   "metadata": {
    "id": "r5LCM5-z7xas"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-mattress",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joined-serbia",
    "outputId": "376a820e-62b6-4c43-ade3-bd42708b7787"
   },
   "outputs": [],
   "source": [
    "# normalisation\n",
    "#Having features on a similar scale can help the model converge more quickly towards the minimum\n",
    "scaler_X = StandardScaler().fit(data)\n",
    "X = scaler_X.transform(data)\n",
    "#check if nan are present on the data after normalization to avoid trouble later\n",
    "if(sum(np.isnan(X)).all()): print(\"Error nan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-snapshot",
   "metadata": {},
   "source": [
    "# Supervised clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-wallet",
   "metadata": {
    "id": "oP0IgqiegYE5"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "plot_flag = False\n",
    "max_k = 7\n",
    "\n",
    "estimators = []\n",
    "for k in range(2,max_k+1):\n",
    "  estimators.append(('k_means_'+str(k), KMeans(n_clusters=k)))\n",
    "\n",
    "\n",
    "try_scores = ['adjusted_rand_score',\n",
    "              'adjusted_mutual_info_score']\n",
    "\n",
    "results = {s:dict() for s in try_scores }\n",
    "titles  = ['2 clusters','3 clusters', '4 clusters']\n",
    "for name, est in estimators:\n",
    "    \n",
    "  est.fit(X)\n",
    "  labels_pred = est.labels_\n",
    "\n",
    "  # SUPERVISED Metrics\n",
    "  # [...]  the (adjusted or unadjusted) Rand index requires knowledge of the \n",
    "  # ground truth classes which is almost never available in practice or requires\n",
    "  # manual assignment by human annotators (as in the supervised learning setting).\n",
    "  results['adjusted_rand_score'][name] = metrics.adjusted_rand_score(unknown_class, labels_pred)\n",
    "\n",
    "  results['adjusted_mutual_info_score'][name] = metrics.adjusted_mutual_info_score(unknown_class, labels_pred)\n",
    "\n",
    "  if plot_flag:\n",
    "\n",
    "    df = pd.DataFrame(X)\n",
    "    df['predicted labels'] = labels_pred\n",
    "    sns.pairplot(df,hue='predicted labels',diag_kws={'palette':'Set2'},plot_kws={'palette':'Set2'})\n",
    "\n",
    "if plot_flag:\n",
    "  # True classes\n",
    "  df = pd.DataFrame(X)\n",
    "  df['true labels'] = unknown_class\n",
    "  sns.pairplot(df,hue='true labels',diag_kws={'palette':'Set2'},plot_kws={'palette':'Set2'})\n",
    "\n",
    "n = len(results.keys())\n",
    "fig,axs = plt.subplots(1,2,figsize=[8*2,4*2])\n",
    "for i,score_name in enumerate(results):\n",
    "    axs.flatten()[i].bar(results[score_name].keys(),results[score_name].values())\n",
    "    axs.flatten()[i].set_title(score_name)\n",
    "    axs.flatten()[i].set_xticks(axs.flatten()[i].get_xticks())\n",
    "    axs.flatten()[i].set_xticklabels(results[score_name].keys(),rotation=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-massage",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "qRkJywrXp_iH",
    "outputId": "ed3de782-30f6-43b7-e03d-235ad411bc37"
   },
   "outputs": [],
   "source": [
    "#let's plot the results\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2,random_state=0)\n",
    "X_r = tsne.fit_transform(X)\n",
    "est = estimators[1][1]\n",
    "pred_y = est.fit_predict(X_r)\n",
    "\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "plt.scatter(X_r[:,0], X_r[:,1], c=unknown_class.values, cmap='viridis', linewidth=0.5);\n",
    "plt.scatter(est.cluster_centers_[:, 0], est.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-dairy",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add TSNE feature\n",
    "Xnew = np.insert(X,0,X_r[:,1],axis=1)\n",
    "Xnew = np.insert(Xnew,0,X_r[:,0],axis=1)\n",
    "X = Xnew\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(X[:, 0], X[:,1], marker='o', s=80, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clustering Examples",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
