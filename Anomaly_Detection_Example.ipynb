{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-funeral",
   "metadata": {},
   "source": [
    "# Anomaly Detection Example\n",
    "\n",
    "<a href=\"https://www.analyticsvidhya.com/blog/2019/02/outlier-detection-python-pyod/\"><img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/02/Outliers.jpeg\" /></a>\n",
    "\n",
    "<blockquote>\n",
    "\n",
    "    “Outliers are not necessarily a bad thing. These are just observations that are not following the same pattern as the other ones. But it can be the case that an outlier is very interesting. For example, if in a biological experiment, a rat is not dead whereas all others are, then it would be very interesting to understand why. This could lead to new scientific discoveries.  So, it is important to detect outliers.”\n",
    "                                                                                                          \n",
    "    – Pierre Lafaye de Micheaux, Author and Statistician\n",
    "</blockquote>\n",
    "\n",
    "The following example was inspired by <a href=\"https://www.analyticsvidhya.com/blog/2019/02/outlier-detection-python-pyod/\">this example</a>.\n",
    "\n",
    "It uses a special Python toolkit dedicated to Outliers Detection called <a href=\"https://pyod.readthedocs.io/en/latest/index.html\">PyOD</a>, additional info are <a href=\"http://www.jmlr.org/papers/volume20/19-011/19-011.pdf\">here</a>. \n",
    "<br />\n",
    "<br />\n",
    "PyOD is a comprehensive and scalable Python toolkit for detecting outlying objects in multivariate data. This exciting yet challenging field is commonly referred as Outlier Detection or Anomaly Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import std packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Import models from PyOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "\n",
    "#Import data-generation tool from PyOD\n",
    "from pyod.utils.data import generate_data, get_outliers_inliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-amount",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(3)\n",
    "outliers_fraction = 0.1\n",
    "# Define six outlier detection tools to be compared\n",
    "#\n",
    "classifiers = {\n",
    "        'Angle-based Outlier Detector (ABOD)': ABOD(contamination=outliers_fraction),\n",
    "        'Histogram-base Outlier Detection (HBOS)': HBOS(contamination=outliers_fraction),\n",
    "        'Cluster-based Local Outlier Factor (CBLOF)':CBLOF(contamination=outliers_fraction,check_estimator=False, random_state=random_state),\n",
    "        'Isolation Forest': IForest(contamination=outliers_fraction,random_state=random_state),\n",
    "        'K Nearest Neighbors (KNN)': KNN(contamination=outliers_fraction),\n",
    "        'Average KNN': KNN(method='mean',contamination=outliers_fraction)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-worse",
   "metadata": {},
   "source": [
    "## Data gathering and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate random data with two features\n",
    "X_train, Y_train,X_test, Y_test = generate_data(n_train=500,n_test=200, n_features=2,random_state=3,contamination=outliers_fraction)\n",
    "\n",
    "\n",
    "# store outliers and inliers in different numpy arrays\n",
    "x_outliers, x_inliers = get_outliers_inliers(X_train,Y_train)\n",
    "xt_outliers, xt_inliers = get_outliers_inliers(X_test,Y_test)\n",
    "\n",
    "\n",
    "n_inliers = len(x_inliers)\n",
    "n_outliers = len(x_outliers)\n",
    "\n",
    "#separate the two features and use it to plot the data \n",
    "F1 = X_train[:,[0]].reshape(-1,1)\n",
    "F2 = X_train[:,[1]].reshape(-1,1)\n",
    "# create a meshgrid \n",
    "xx , yy = np.meshgrid(np.linspace(-10, 10, 200), np.linspace(-10, 10, 200))\n",
    "\n",
    "# scatter plot \n",
    "plt.figure(figsize=[15,9])\n",
    "plt.scatter(x_outliers[:,0],x_outliers[:,1],c='black',edgecolor='k',label='Outliers')\n",
    "plt.scatter(x_inliers[:,0],x_inliers[:,1],c='white',edgecolor='k',label='Inliers')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-convenience",
   "metadata": {},
   "source": [
    "## Train different models evaluate and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the figure size\n",
    "plt.figure(figsize=(19, 20))\n",
    "dfx = pd.DataFrame(X_train)\n",
    "dfx['y'] = Y_train\n",
    "\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()) :\n",
    "    # fit the dataset to the model\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    # predict raw anomaly score\n",
    "    scores_pred = clf.decision_function(X_train)*-1\n",
    "\n",
    "    # prediction of a datapoint category outlier or inlier\n",
    "    y_pred = clf.predict(X_train)\n",
    "\n",
    "    # no of errors in prediction\n",
    "    n_errors = (y_pred != Y_train).sum()\n",
    "\n",
    "    dfx['outlier'] = y_pred.tolist()\n",
    "    \n",
    "    # IX1 - inlier feature 1,  IX2 - inlier feature 2\n",
    "    IX1 =  np.array(dfx[0][dfx['outlier'] == 0]).reshape(-1,1)\n",
    "    IX2 =  np.array(dfx[1][dfx['outlier'] == 0]).reshape(-1,1)\n",
    "    \n",
    "    # OX1 - outlier feature 1, OX2 - outlier feature 2\n",
    "    OX1 =  dfx[0][dfx['outlier'] == 1].values.reshape(-1,1)\n",
    "    OX2 =  dfx[1][dfx['outlier'] == 1].values.reshape(-1,1)\n",
    "    \n",
    "        # True - outlier feature 1, OX2 - outlier feature 2\n",
    "    TX1 =  dfx[0][dfx['y'] == 1].values.reshape(-1,1)\n",
    "    TX2 =  dfx[1][dfx['y'] == 1].values.reshape(-1,1)\n",
    "    \n",
    "    text ='No of mis-detected outliers : '+clf_name+\" \"+str(n_errors)\n",
    "    if(n_errors==0):\n",
    "        text =\"\\033[1m\"+\"\\033[91m\"+'No of mis-detected outliers : '+clf_name+\" \"+str(n_errors)+\"\\033[0m\"\n",
    "    print(text)\n",
    "\n",
    "    # rest of the code is to create the visualization\n",
    "\n",
    "    # threshold value to consider a datapoint inlier or outlier\n",
    "    threshold = stats.scoreatpercentile(scores_pred,100 *outliers_fraction)\n",
    "   \n",
    "    # decision function calculates the raw anomaly score for every point\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    subplot = plt.subplot(2, 3, i + 1)\n",
    "\n",
    "    # fill blue colormap from minimum anomaly score to threshold value\n",
    "    subplot.contourf(xx, yy, Z, levels = np.linspace(Z.min(), threshold, 10),cmap=plt.cm.Blues_r)\n",
    "\n",
    "    # draw red contour line where anomaly score is equal to threshold\n",
    "    a = subplot.contour(xx, yy, Z, levels=[threshold],linewidths=2, colors='red')\n",
    "\n",
    "    # fill orange contour lines where range of anomaly score is from threshold to maximum anomaly score\n",
    "    subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],colors='orange')\n",
    "\n",
    "    # scatter plot of inliers with white dots \n",
    "    b = subplot.scatter(IX1,IX2, c='white',s=100, edgecolor='k')\n",
    "    # scatter plot of detected outliers with black dots\n",
    "    c = subplot.scatter(OX1,OX2, c='black',s=100, edgecolor='k')\n",
    "    # scatter plot of true outliers with red dots\n",
    "    d = subplot.scatter(x_outliers[:,0],x_outliers[:,1], c='red',s=20,)\n",
    "    subplot.axis('tight')\n",
    "\n",
    "    subplot.legend(\n",
    "        [a.collections[0], b, c, d],\n",
    "        ['learned decision function', 'inliers', 'detected outliers','true outliers'],\n",
    "        loc='lower right')\n",
    "\n",
    "    subplot.set_title(clf_name)\n",
    "    subplot.set_xlim((-10, 10))\n",
    "    subplot.set_ylim((-10, 10))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-breeding",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the figure size\n",
    "plt.figure(figsize=(19, 20))\n",
    "dfxt = pd.DataFrame(X_test)\n",
    "dfxt['y'] = Y_test\n",
    "\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()) :\n",
    "    \n",
    "    # predict raw anomaly score\n",
    "    scores_pred = clf.decision_function(X_test)*-1\n",
    "\n",
    "    # prediction of a datapoint category outlier or inlier\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # no of errors in prediction\n",
    "    n_errors = (y_pred != Y_test).sum()\n",
    "\n",
    "    dfxt['outlier'] = y_pred.tolist()\n",
    "    \n",
    "    # IX1 - inlier feature 1,  IX2 - inlier feature 2\n",
    "    IX1 =  np.array(dfxt[0][dfx['outlier'] == 0]).reshape(-1,1)\n",
    "    IX2 =  np.array(dfxt[1][dfx['outlier'] == 0]).reshape(-1,1)\n",
    "    \n",
    "    # OX1 - outlier feature 1, OX2 - outlier feature 2\n",
    "    OX1 =  dfxt[0][dfxt['outlier'] == 1].values.reshape(-1,1)\n",
    "    OX2 =  dfxt[1][dfxt['outlier'] == 1].values.reshape(-1,1)\n",
    "    \n",
    "        # True - outlier feature 1, OX2 - outlier feature 2\n",
    "    TX1 =  dfxt[0][dfxt['y'] == 1].values.reshape(-1,1)\n",
    "    TX2 =  dfxt[1][dfxt['y'] == 1].values.reshape(-1,1)\n",
    "    \n",
    "    text ='No of mis-detected outliers : '+clf_name+\" \"+str(n_errors)\n",
    "    if(n_errors==0):\n",
    "        text =\"\\033[1m\"+\"\\033[91m\"+'No of mis-detected outliers : '+clf_name+\" \"+str(n_errors)+\"\\033[0m\"\n",
    "    print(text)\n",
    "\n",
    "    # rest of the code is to create the visualization\n",
    "\n",
    "    # threshold value to consider a datapoint inlier or outlier\n",
    "    threshold = stats.scoreatpercentile(scores_pred,100 *outliers_fraction)\n",
    "   \n",
    "    # decision function calculates the raw anomaly score for every point\n",
    "    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) * -1\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    subplot = plt.subplot(2, 3, i + 1)\n",
    "\n",
    "    # fill blue colormap from minimum anomaly score to threshold value\n",
    "    subplot.contourf(xx, yy, Z, levels = np.linspace(Z.min(), threshold, 10),cmap=plt.cm.Blues_r)\n",
    "\n",
    "    # draw red contour line where anomaly score is equal to threshold\n",
    "    a = subplot.contour(xx, yy, Z, levels=[threshold],linewidths=2, colors='red')\n",
    "\n",
    "    # fill orange contour lines where range of anomaly score is from threshold to maximum anomaly score\n",
    "    subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],colors='orange')\n",
    "\n",
    "    # scatter plot of inliers with white dots\n",
    "    #b = subplot.scatter(X_train[:-n_outliers, 0], X_train[:-n_outliers, 1], c='white',s=100, edgecolor='k') \n",
    "    b = subplot.scatter(IX1,IX2, c='white',s=100, edgecolor='k')\n",
    "    # scatter plot of outliers with black dots\n",
    "    #c = subplot.scatter(X_train[-n_outliers:, 0], X_train[-n_outliers:, 1], c='black',s=100, edgecolor='k')\n",
    "    c = subplot.scatter(OX1,OX2, c='black',s=100, edgecolor='k')\n",
    "    \n",
    "    # scatter plot of true outliers with red dots\n",
    "    d = subplot.scatter(xt_outliers[:,0],xt_outliers[:,1], c='red',s=20,)\n",
    "    subplot.axis('tight')\n",
    "\n",
    "    subplot.legend(\n",
    "        [a.collections[0], b, c, d],\n",
    "        ['learned decision function', 'inliers', 'detected outliers','true outliers'],\n",
    "        loc='lower right')\n",
    "\n",
    "    subplot.set_title(clf_name)\n",
    "    subplot.set_xlim((-10, 10))\n",
    "    subplot.set_ylim((-10, 10))\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
